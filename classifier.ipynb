{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getAllDoxyDonkeyPosts(url,links):\n",
    "    request = Request(url)\n",
    "    response = urlopen(request)\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    for a in soup.findAll('a'):\n",
    "        try:\n",
    "            url = a['href']\n",
    "            title = a['title']\n",
    "            if title == \"Older Posts\":\n",
    "                links.append(url)\n",
    "                getAllDoxyDonkeyPosts(url,links)\n",
    "        except:\n",
    "            title = \"\"\n",
    "    return\n",
    "\n",
    "blogUrl = \"http://doxydonkey.blogspot.com\"\n",
    "links = []\n",
    "getAllDoxyDonkeyPosts(blogUrl,links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDoxyDonkeyText(testUrl):\n",
    "    request = Request(testUrl)\n",
    "    response = urlopen(request)\n",
    "    soup = BeautifulSoup(response, \"lxml\")\n",
    "    mydivs = soup.findAll(\"div\", {\"class\":'post-body'})\n",
    "    \n",
    "    posts =[]\n",
    "    for div in mydivs:\n",
    "        posts+=map(lambda p:p.text.encode('ascii', errors='replace').replace(b\"?\",b\" \"), div.findAll(\"li\"))\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doxyDonkeyPosts = []\n",
    "for link in links:\n",
    "    doxyDonkeyPosts+=getDoxyDonkeyText(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5,min_df=2,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2804x13220 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 280835 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(doxyDonkeyPosts)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13220 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 108 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters = 3, init = 'k-means++', max_iter = 100, n_init = 1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 5188.507\n",
      "Iteration  1, inertia 2686.429\n",
      "Iteration  2, inertia 2681.372\n",
      "Iteration  3, inertia 2678.465\n",
      "Iteration  4, inertia 2675.570\n",
      "Iteration  5, inertia 2674.003\n",
      "Iteration  6, inertia 2673.083\n",
      "Iteration  7, inertia 2672.594\n",
      "Iteration  8, inertia 2672.189\n",
      "Iteration  9, inertia 2671.787\n",
      "Iteration 10, inertia 2671.368\n",
      "Iteration 11, inertia 2671.100\n",
      "Iteration 12, inertia 2670.796\n",
      "Iteration 13, inertia 2670.472\n",
      "Iteration 14, inertia 2670.234\n",
      "Iteration 15, inertia 2669.951\n",
      "Iteration 16, inertia 2669.529\n",
      "Iteration 17, inertia 2668.835\n",
      "Iteration 18, inertia 2667.720\n",
      "Iteration 19, inertia 2667.289\n",
      "Iteration 20, inertia 2667.074\n",
      "Iteration 21, inertia 2666.804\n",
      "Iteration 22, inertia 2666.524\n",
      "Iteration 23, inertia 2666.318\n",
      "Iteration 24, inertia 2666.181\n",
      "Iteration 25, inertia 2666.071\n",
      "Iteration 26, inertia 2666.001\n",
      "Iteration 27, inertia 2665.932\n",
      "Iteration 28, inertia 2665.896\n",
      "Iteration 29, inertia 2665.858\n",
      "Iteration 30, inertia 2665.836\n",
      "Iteration 31, inertia 2665.829\n",
      "Iteration 32, inertia 2665.826\n",
      "Converged at iteration 32: center shift 0.000000e+00 within tolerance 7.307995e-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=3, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=True)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2], dtype=int32), array([1987,  390,  427]))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(km.labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text={}\n",
    "for i,cluster in enumerate(km.labels_):\n",
    "    oneDocument = doxyDonkeyPosts[i].decode(\"utf-8\")\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = oneDocument\n",
    "    else:\n",
    "        text[cluster] += oneDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "from heapq import nlargest\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_stopwords = set(stopwords.words('english') + list(punctuation)+[\"million\",\"billion\",\"year\",\"millions\",\"billions\",\"y/y\",\"'s\",\"''\",\"``\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = {}\n",
    "counts={}\n",
    "for cluster in range(3):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent=[word for word in word_sent if word not in _stopwords]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    counts[cluster]=freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unique_keys={}\n",
    "for cluster in range(3):   \n",
    "    other_clusters=list(set(range(3))-set([cluster]))\n",
    "    keys_other_clusters=set(keywords[other_clusters[0]]).union(set(keywords[other_clusters[1]]))\n",
    "    unique=set(keywords[cluster])-keys_other_clusters\n",
    "    unique_keys[cluster]=nlargest(10, unique, key=counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['uber',\n",
       "  'india',\n",
       "  'round',\n",
       "  'chinese',\n",
       "  'funding',\n",
       "  'capital',\n",
       "  'raised',\n",
       "  'investment',\n",
       "  'e-commerce',\n",
       "  'valuation'],\n",
       " 1: ['ads',\n",
       "  'video',\n",
       "  'use',\n",
       "  'products',\n",
       "  'product',\n",
       "  'search',\n",
       "  'apps',\n",
       "  'pay',\n",
       "  'ad',\n",
       "  'way'],\n",
       " 2: ['quarter',\n",
       "  'share',\n",
       "  'profit',\n",
       "  'rose',\n",
       "  'earnings',\n",
       "  'analysts',\n",
       "  'cents',\n",
       "  'per',\n",
       "  'fell',\n",
       "  'net']}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article = \"Pinterest has raised $150 million in a new round of funding. The new deal values Pinterest at $12.3 billion, according to a company spokesperson, up from a valuation of $11 billion when it last raised funding two years ago.The round came from Pinterestâ€™s existing investors, but the company is not saying which ones. Bloomberg first reported the news. Pinterest says it plans to use the money to help build its new visual search technology, which lets users employ images instead of keywords to find things on the service. The money will also be used to help grow its user base outside the United States. Around 40 percent of Pinterestâ€™s users are in the U.S. Pinterest has raised well over $1 billion since it was founded seven years ago. The companyâ€™s business is finally starting to pick up; it expects to make more than $500 million in revenue this year, a 66 percent jump over last year, and more than Snapchat and Twitter made in the years before their respective IPOs.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=20, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=20)\n",
    "classifier.fit(X,km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test=vectorizer.transform([article.encode('ascii',errors='ignore')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x13220 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 68 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
